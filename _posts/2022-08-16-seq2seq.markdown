---
# multilingual page pair id, this must pair with translations of this page. (This name must be unique)
lng_pair: id_Examples
title: seq2seq

# post specific
# if not specified, .name will be used from _data/owner/[language].yml
author: Mr. Green's Workshop
# multiple category is not supported
category: jekyll
# multiple tag entries are possible
tags: [jekyll, sample, example post]
# thumbnail image for post
img: ":post_pic1.jpg"
# disable comments on this page
#comments_disable: true

# publish date
date: 2022-08-16 20:30:06 +0900

# seo
# if not specified, date will be used.
#meta_modify_date: 2022-08-16 20:30:06 +0900
# check the meta_common_description in _data/owner/[language].yml
#meta_description: ""

# optional
# if you enabled image_viewer_posts you don't need to enable this. This is only if image_viewer_posts = false
#image_viewer_on: true
# if you enabled image_lazy_loader_posts you don't need to enable this. This is only if image_lazy_loader_posts = false
#image_lazy_loader_on: true
# exclude from on site search
#on_site_search_exclude: true
# exclude from search engines
#search_engine_exclude: true
# to disable this page, simply set published: false or delete this file
#published: false
---

<!-- outline-start -->

This is an example page to display markdown related styles for Mr. Green Jekyll Theme.

<!-- outline-end -->

### seq2seq
{:data-align="center"}
seq2seq는 encoder-decoder 모델이라고도 한다.  
  
  
  
### 초창기 기계 번역
![image](https://user-images.githubusercontent.com/42092560/184919250-5eaafb53-b4c1-43bc-aee0-0316eb6bb613.png)  

초창기 기계 번역은 rnn을 하나만 사용하였다.  
  
이는 입력과 출력의 토큰개수가 같다고 가정해야 하는 문제점과 한국어와 영어 같이 어순이 다른경우  
  
좋은 결과를 낼 수 없었다.  
  
이를 해결 하기 위해 rnn을 두개를 사용하여 하나는 encoder, 하나는 decoder로 사용하도록 한다.  
  
### seq2seq의 구성
  
![image](https://user-images.githubusercontent.com/42092560/184922496-8307fe14-cd9a-466d-949e-fffdf01ebee5.png)  
  
위의 문제를 해결하기 위해 인코더에서 문맥 벡터를 추출한다.  
  
이후 문맥 벡터로부터 디코더가 번역 결과를 추론한다.  
  
이때 문맥 벡터는 인코더의 마지막 은닉계층의 벡터를 사용한다.  
  
디코더에서 고정된 크기의 문맥 벡터를 받아서 은닉계층의 벡터를 뽑아낸 뒤 간단한 affine layer를 거쳐서 값을 출력한다.  
  
번역의 경우 나라마다의 문법때문에 입력개수와 출력개수가 다를 수 있다.  
  
근데 고정된 크기의 문맥 벡터라면 만약 학습을 할때 짧은 문장만 학습하다가 테스트에 갑자기 긴 문장이 나오는 경우  
  
벡터가 문맥 정보를 다담지 못하여 성능저하가 일어나지 않을까 생각이 든다.  
  
※ 번역같은 경우 입력길이가 다른 경우가 있다.  
  
이때 미니배치처리를 하기위해서 입력길이를 같게 해줘야 하는데 이때 padding을 사용한다.  
  
padding은 입력길이를 같게 하기 위해 뒤에 의미없는 값을 넣어 주는 것을 말한다.  
ex) |자|연|어|는|어|렵|다|
    |아|닌|데| 0| 0| 0| 0|
